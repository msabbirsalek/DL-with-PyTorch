{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4f24d37",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-21T07:41:37.684496Z",
          "iopub.status.busy": "2022-02-21T07:41:37.683584Z",
          "iopub.status.idle": "2022-02-21T07:41:39.455843Z",
          "shell.execute_reply": "2022-02-21T07:41:39.455086Z"
        },
        "papermill": {
          "duration": 1.813167,
          "end_time": "2022-02-21T07:41:39.456007",
          "exception": false,
          "start_time": "2022-02-21T07:41:37.642840",
          "status": "completed"
        },
        "tags": [],
        "id": "b4f24d37"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a0aecd1",
      "metadata": {
        "papermill": {
          "duration": 0.030036,
          "end_time": "2022-02-21T07:41:39.520277",
          "exception": false,
          "start_time": "2022-02-21T07:41:39.490241",
          "status": "completed"
        },
        "tags": [],
        "id": "8a0aecd1"
      },
      "source": [
        "**Load CIFAR10 Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca636298",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-21T07:41:39.589203Z",
          "iopub.status.busy": "2022-02-21T07:41:39.586228Z",
          "iopub.status.idle": "2022-02-21T07:42:00.417700Z",
          "shell.execute_reply": "2022-02-21T07:42:00.417081Z"
        },
        "papermill": {
          "duration": 20.867302,
          "end_time": "2022-02-21T07:42:00.417855",
          "exception": false,
          "start_time": "2022-02-21T07:41:39.550553",
          "status": "completed"
        },
        "tags": [],
        "id": "ca636298",
        "outputId": "4e496bb2-70a1-48a0-d7ac-59bbc73452b9",
        "colab": {
          "referenced_widgets": [
            "ed492603b37044db818d0b05b59f3064"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz to ./cifar10.tgz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed492603b37044db818d0b05b59f3064",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/135107811 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Dowload the dataset\n",
        "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
        "download_url(dataset_url, '.')\n",
        "\n",
        "# Extract from archive\n",
        "with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
        "    tar.extractall(path='./data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7167b371",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-21T07:42:00.488163Z",
          "iopub.status.busy": "2022-02-21T07:42:00.485950Z",
          "iopub.status.idle": "2022-02-21T07:42:00.492536Z",
          "shell.execute_reply": "2022-02-21T07:42:00.493250Z"
        },
        "papermill": {
          "duration": 0.043758,
          "end_time": "2022-02-21T07:42:00.493475",
          "exception": false,
          "start_time": "2022-02-21T07:42:00.449717",
          "status": "completed"
        },
        "tags": [],
        "id": "7167b371",
        "outputId": "3ae1cfc7-3c1e-4d31-ceb3-7a2d48bf6b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['train', 'test']\n",
            "['ship', 'automobile', 'airplane', 'deer', 'dog', 'bird', 'horse', 'frog', 'truck', 'cat']\n"
          ]
        }
      ],
      "source": [
        "data_dir = './data/cifar10'\n",
        "\n",
        "print(os.listdir(data_dir))\n",
        "classes = os.listdir(data_dir + \"/train\")\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "134a8882",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-21T07:42:00.566324Z",
          "iopub.status.busy": "2022-02-21T07:42:00.565285Z",
          "iopub.status.idle": "2022-02-21T07:42:00.574774Z",
          "shell.execute_reply": "2022-02-21T07:42:00.574157Z"
        },
        "papermill": {
          "duration": 0.049022,
          "end_time": "2022-02-21T07:42:00.574939",
          "exception": false,
          "start_time": "2022-02-21T07:42:00.525917",
          "status": "completed"
        },
        "tags": [],
        "id": "134a8882",
        "outputId": "ca937738-1b9d-4ac9-b885-71550bc18526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of training examples for automobiles: 5000\n",
            "['1912.png', '3350.png', '1947.png', '1384.png', '1592.png']\n"
          ]
        }
      ],
      "source": [
        "automobile_images = os.listdir(data_dir + \"/train/automobile\")\n",
        "print('No. of training examples for automobiles:', len(automobile_images))\n",
        "print(automobile_images[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a97a49f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-21T07:42:00.646448Z",
          "iopub.status.busy": "2022-02-21T07:42:00.645464Z",
          "iopub.status.idle": "2022-02-21T07:42:00.963529Z",
          "shell.execute_reply": "2022-02-21T07:42:00.964218Z"
        },
        "papermill": {
          "duration": 0.356711,
          "end_time": "2022-02-21T07:42:00.964456",
          "exception": false,
          "start_time": "2022-02-21T07:42:00.607745",
          "status": "completed"
        },
        "tags": [],
        "id": "0a97a49f",
        "outputId": "934b4c89-aec8-4ab6-ff6a-3fd5aac1b5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of the dataset: 50000\n"
          ]
        }
      ],
      "source": [
        "dataset = ImageFolder(data_dir+'/train', transform=ToTensor())\n",
        "print('Length of the dataset:', len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79484884",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-21T07:42:01.039885Z",
          "iopub.status.busy": "2022-02-21T07:42:01.038702Z",
          "iopub.status.idle": "2022-02-21T07:42:01.042044Z",
          "shell.execute_reply": "2022-02-21T07:42:01.041501Z"
        },
        "papermill": {
          "duration": 0.04433,
          "end_time": "2022-02-21T07:42:01.042223",
          "exception": false,
          "start_time": "2022-02-21T07:42:00.997893",
          "status": "completed"
        },
        "tags": [],
        "id": "79484884"
      },
      "outputs": [],
      "source": [
        "def show_image(img, label):\n",
        "    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n",
        "    plt.imshow(img.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08467fb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-21T07:42:01.120328Z",
          "iopub.status.busy": "2022-02-21T07:42:01.119275Z",
          "iopub.status.idle": "2022-02-21T07:42:01.226987Z",
          "shell.execute_reply": "2022-02-21T07:42:01.226244Z"
        },
        "papermill": {
          "duration": 0.151584,
          "end_time": "2022-02-21T07:42:01.227351",
          "exception": true,
          "start_time": "2022-02-21T07:42:01.075767",
          "status": "failed"
        },
        "tags": [],
        "id": "c08467fb",
        "outputId": "852fe78d-7b92-4ee2-8295-1e5df4ed4b57"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'show_example' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_27/1056112354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'show_example' is not defined"
          ]
        }
      ],
      "source": [
        "show_image(*dataset[100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eff12ce",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "3eff12ce"
      },
      "outputs": [],
      "source": [
        "show_example(*dataset[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1edec6b",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "a1edec6b"
      },
      "source": [
        "**Preapre datasets for trainning and validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d596b19",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "1d596b19"
      },
      "outputs": [],
      "source": [
        "# Set a random seed to always use the same trainning subset\n",
        "random_seed = 51\n",
        "torch.manual_seed(random_seed);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb2f3b10",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "bb2f3b10"
      },
      "outputs": [],
      "source": [
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7531cc5e",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "7531cc5e"
      },
      "outputs": [],
      "source": [
        "batch_size=128\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f74257c7",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "f74257c7"
      },
      "outputs": [],
      "source": [
        "def show_imagebatch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83799dcf",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "83799dcf"
      },
      "outputs": [],
      "source": [
        "show_imagebatch(train_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b212d12",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "8b212d12"
      },
      "source": [
        "**Define CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "136ec6ac",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "136ec6ac"
      },
      "outputs": [],
      "source": [
        "def apply_kernel(image, kernel):\n",
        "    ri, ci = image.shape       # image dimensions\n",
        "    rk, ck = kernel.shape      # kernel dimensions\n",
        "    ro, co = ri-rk+1, ci-ck+1  # output dimensions\n",
        "    output = torch.zeros([ro, co])\n",
        "    for i in range(ro): \n",
        "        for j in range(co):\n",
        "            output[i,j] = torch.sum(image[i:i+rk,j:j+ck] * kernel)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35066022",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "35066022"
      },
      "outputs": [],
      "source": [
        "class ClassifyImages(nn.Module):\n",
        "    def train(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        acc = accuracy(out, labels)         # Calculate accuracy\n",
        "        return loss, acc\n",
        "    \n",
        "    def validate(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['train_acc'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38eeda38",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "38eeda38"
      },
      "outputs": [],
      "source": [
        "class Cifar10CnnModel0(ClassifyImages):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            #Conv Layer1: channels 3 to 32\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            #Conv Layer2: channels 32 to 64\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
        "\n",
        "            #Conv Layer3: channels 64 to 128\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            #Conv Layer4: channels 128 to 128\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
        "\n",
        "            #Conv Layer5: channels 128 to 256\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            #Conv Layer6: channels 256 to 256\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
        "\n",
        "            nn.Flatten(), \n",
        "            #Linear Layer1: 256*4*4 to 1024\n",
        "            nn.Linear(256*4*4, 1024),\n",
        "            nn.ReLU(),\n",
        "            #Linear Layer2: 1024 to 512\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            #Linear Layer3: 512 to 10\n",
        "            nn.Linear(512, 10))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73359ab1",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "73359ab1"
      },
      "outputs": [],
      "source": [
        "model0 = Cifar10CnnModel0()\n",
        "model0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d8c0f2",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "e9d8c0f2"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0458274",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "b0458274"
      },
      "outputs": [],
      "source": [
        "count_parameters(model0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef9571a1",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ef9571a1"
      },
      "source": [
        "**Use GPU for trainning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a3aee9f",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "3a3aee9f"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96319697",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "96319697"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b20ab98f",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "b20ab98f"
      },
      "source": [
        "**Place dataloaders and the model into GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a6e5d62",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "9a6e5d62"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b69cbf0",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "5b69cbf0"
      },
      "source": [
        "**Model Trainning Phase**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddaa913b",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ddaa913b"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validate(batch) for batch in val_loader]\n",
        "    return model.validation_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Trainning Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        train_accuracies = []\n",
        "        for batch in train_loader:\n",
        "            loss, acc = model.train(batch)\n",
        "            train_losses.append(loss)\n",
        "            train_accuracies.append(acc)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['train_acc'] = torch.stack(train_accuracies).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6abef7",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ed6abef7"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "    \n",
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9181fb10",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "9181fb10"
      },
      "outputs": [],
      "source": [
        "#Sanity checking\n",
        "evaluate(model0, val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f1cebb",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "80f1cebb"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "lr = 0.001\n",
        "opt_func = torch.optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d38b3015",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "d38b3015"
      },
      "outputs": [],
      "source": [
        "#Start tranning\n",
        "history0 = fit(num_epochs, lr, model0, train_dl, val_dl, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1e2070",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "af1e2070"
      },
      "outputs": [],
      "source": [
        "plot_losses(history0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "243b0c79",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "243b0c79"
      },
      "outputs": [],
      "source": [
        "plot_accuracies(history0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab55b7ed",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ab55b7ed"
      },
      "outputs": [],
      "source": [
        "train_losses0 = [x['train_loss'] for x in history]\n",
        "train_accuracies0 = [x['train_acc'] for x in history]\n",
        "val_accuracies0 = [x['val_acc'] for x in history]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58a40d66",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "58a40d66"
      },
      "source": [
        "**Save the trained model, trainning losses and accuracies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4291182a",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "4291182a"
      },
      "outputs": [],
      "source": [
        "torch.save(model0.state_dict(), 'HW_1_2_CIFAR10_model0.pth')\n",
        "pd.DataFrame(train_losses0).to_csv('HW_1_2_CIFAR10_model0_train_losses.csv',index=False)\n",
        "pd.DataFrame(train_accuracies0).to_csv('HW_1_2_CIFAR10_model0_train_accuracies.csv',index=False)\n",
        "pd.DataFrame(val_accuracies0).to_csv('HW_1_2_CIFAR10_model0_val_accuracies.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 35.178476,
      "end_time": "2022-02-21T07:42:02.475733",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-02-21T07:41:27.297257",
      "version": "2.3.3"
    },
    "colab": {
      "name": "hw-1-1-cifar10.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}